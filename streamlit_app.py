import streamlit as st
import os
import torch
import numpy as np
from PIL import Image
import cv2
import requests
from pathlib import Path

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ---
st.set_page_config(page_title="–£–¥–∞–ª–µ–Ω–∏–µ –≤–æ–¥—è–Ω—ã—Ö –∑–Ω–∞–∫–æ–≤", layout="wide")
st.title("üßº –£–¥–∞–ª–µ–Ω–∏–µ –≤–æ–¥—è–Ω—ã—Ö –∑–Ω–∞–∫–æ–≤ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")

# –ü–∞–ø–∫–∞ –¥–ª—è –º–æ–¥–µ–ª–µ–π
models_dir = Path("models")
models_dir.mkdir(exist_ok=True)

# URLs –º–æ–¥–µ–ª–µ–π
U2NET_URL = "https://github.com/xuebinqin/U-2-Net/releases/download/v1.0.0/u2net.pth"
LAMA_URL = "https://huggingface.co/aimetis/lama/resolve/main/big-lama/models/best.ckpt"

U2NET_PATH = models_dir / "u2net.pth"
LAMA_PATH = models_dir / "lama.pth"  # –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º .ckpt ‚Üí .pth

# --- –§—É–Ω–∫—Ü–∏—è: —Å–∫–∞—á–∞—Ç—å –º–æ–¥–µ–ª—å ---
def download_model(url: str, path: Path, name: str):
    if path.exists():
        st.info(f"‚úÖ {name} —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞.")
        return True

    st.info(f"üì• –ó–∞–≥—Ä—É–∂–∞—é {name}...")
    try:
        with requests.get(url, stream=True) as r:
            r.raise_for_status()
            total_size = int(r.headers.get('content-length', 0))
            with open(path, 'wb') as f, st.spinner(f"–°–∫–∞—á–∏–≤–∞–Ω–∏–µ {name}..."):
                downloaded = 0
                for chunk in r.iter_content(chunk_size=8192):
                    f.write(chunk)
                    downloaded += len(chunk)
                    if total_size > 0:
                        progress = downloaded / total_size
                        st.progress(progress)
        st.success(f"‚úÖ {name} —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞.")
        return True
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {name}: {e}")
        return False

# --- –°–∫–∞—á–∏–≤–∞–µ–º –º–æ–¥–µ–ª–∏ ---
if not download_model(U2NET_URL, U2NET_PATH, "U2-Net"):
    st.stop()

if not download_model(LAMA_URL, LAMA_PATH, "LaMa (big-lama)"):
    st.stop()

# --- –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π ---
@st.cache_resource
def load_models():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    st.info(f"üîß –ò—Å–ø–æ–ª—å–∑—É–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")

    # U2-Net
    try:
        import u2net
        model_u2net = u2net.U2NET(3, 1)
        model_u2net.load_state_dict(torch.load(U2NET_PATH, map_location=device))
        model_u2net.to(device).eval()
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ U2-Net: {e}")
        return None, device

    # LaMa
    try:
        from lama_cleaner.model_manager import ModelManager
        from lama_cleaner.schema import Config
        model_lama = ModelManager(name="lama", device=device)
        config = Config(indoor=False)
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ LaMa: {e}")
        return None, device

    return (model_u2net, model_lama, config), device

# --- –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª–∏ ---
models_data, device = load_models()
if models_data is None:
    st.stop()

u2net_model, lama_model, lama_config = models_data

st.success("‚úÖ –í—Å–µ –º–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏ –≥–æ—Ç–æ–≤—ã –∫ —Ä–∞–±–æ—Ç–µ!")

# --- u2net.py (–≤–Ω—É—Ç—Ä–∏ –∫–æ–¥–∞!) ---
# –ü–æ–¥–∫–ª—é—á–∞–µ–º —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é U2NET, –µ—Å–ª–∏ —Ñ–∞–π–ª–∞ –Ω–µ—Ç
U2NET_CODE = '''
import torch
import torch.nn as nn
import torch.nn.functional as F

class REBNCONV(nn.Module):
    def __init__(self, in_ch=3, out_ch=3, dirate=1):
        super(REBNCONV, self).__init__()
        self.conv = nn.Conv2d(in_ch, out_ch, 3, padding=1*dirate, dilation=1*dirate)
        self.bn = nn.BatchNorm2d(out_ch)
        self.relu = nn.ReLU(inplace=True)

    def forward(self, x):
        x = self.conv(x)
        x = self.bn(x)
        return self.relu(x)

def _upsample_like(x, size):
    return F.interpolate(x, size=size, mode='bilinear', align_corners=False)

class U2NET(nn.Module):
    def __init__(self, in_ch=3, out_ch=1):
        super(U2NET, self).__init__()
        self.stage1 = REBNCONV(in_ch, 64)
        self.pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        self.stage2 = REBNCONV(64, 64)
        self.outconv = nn.Conv2d(64, out_ch, 1)

    def forward(self, x):
        hx = x
        hx1 = self.stage1(hx)
        hx = self.pool1(hx1)
        hx2 = self.stage2(hx)
        d1 = self.outconv(hx1)
        return torch.sigmoid(d1),
'''

# –ü—Ä–æ–≤–µ—Ä–∏–º, –µ—Å—Ç—å –ª–∏ u2net.py
if not os.path.exists("u2net.py"):
    with open("u2net.py", "w") as f:
        f.write(U2NET_CODE)
    st.info("üìù –§–∞–π–ª `u2net.py` —Å–æ–∑–¥–∞–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏.")

# –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥—É–ª—å
import importlib
import u2net
importlib.reload(u2net)

# --- –§—É–Ω–∫—Ü–∏—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ ---
def segment_watermark(image: Image.Image):
    img_np = np.array(image)
    h, w = img_np.shape[:2]
    img_tensor = torch.from_numpy(img_np.transpose(2, 0, 1)).float().unsqueeze(0) / 255.0
    img_tensor = img_tensor.to(device)

    with torch.no_grad():
        pred = u2net_model(img_tensor)[0]
        pred = torch.sigmoid(pred).squeeze().cpu().numpy()
    
    mask = (pred * 255).astype(np.uint8)
    _, binary_mask = cv2.threshold(mask, 128, 255, cv2.THRESH_BINARY)
    return cv2.resize(binary_mask, (w, h), interpolation=cv2.INTER_NEAREST)

# --- –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –∑–∞–≥—Ä—É–∑–∫–∏ ---
uploaded_file = st.file_uploader("üì∑ –ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", type=["png", "jpg", "jpeg"])

if uploaded_file is not None:
    image = Image.open(uploaded_file).convert("RGB")
    img_np = np.array(image)

    col1, col2 = st.columns(2)

    with col1:
        st.subheader("–û—Ä–∏–≥–∏–Ω–∞–ª")
        st.image(image, use_column_width=True)

    if st.button("üßπ –£–¥–∞–ª–∏—Ç—å –≤–æ–¥—è–Ω–æ–π –∑–Ω–∞–∫"):
        with st.spinner("–û–±—Ä–∞–±–æ—Ç–∫–∞..."):

            # –ü–æ–ª—É—á–∞–µ–º –º–∞—Å–∫—É
            mask = segment_watermark(image)

            # –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ
            try:
                input_bgr = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)
                result_bgr = lama_model(image=input_bgr, mask=mask, config=lama_config)
                result_rgb = cv2.cvtColor(result_bgr, cv2.COLOR_BGR2RGB)
                result_image = Image.fromarray(result_rgb)

                with col2:
                    st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç")
                    st.image(result_image, use_column_width=True)

                # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ —Å–∫–∞—á–∏–≤–∞–Ω–∏—é
                from io import BytesIO
                buf = BytesIO()
                result_image.save(buf, format="PNG")
                byte_img = buf.getvalue()

                st.download_button(
                    label="‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å –æ—á–∏—â–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ",
                    data=byte_img,
                    file_name=f"cleaned_{uploaded_file.name.split('.')[0]}.png",
                    mime="image/png"
                )

                with st.expander("üîç –ü–æ–∫–∞–∑–∞—Ç—å –º–∞—Å–∫—É"):
                    st.image(mask, width=300, caption="–ú–∞—Å–∫–∞ –≤–æ–¥—è–Ω–æ–≥–æ –∑–Ω–∞–∫–∞")

            except Exception as e:
                st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–∏: {e}")
